{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Authorship Information\n","__author__ = \"Arif Haidari\"<br>\n","__credits__ = [\"Bernd Brinkmann\", \"Luigi Menale\", \"Alex Tavkhelidze\", \"Romain Lesieur\"]<br>\n","__status__ = \"Development\"<br>\n","__project__ = \"Plant Recognition\"<br>\n","__scope__ = \"DataScientest's Bootcamp in Data Science\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ydlx8w6WNwJd"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from skimage.feature import hog, local_binary_pattern\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from xgboost import XGBClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bHbiHhrPRE1"},"outputs":[],"source":["# image classification using Bag of Visual Words (BoVW)\n","# Special-technique-for-image-classification\n","# source:\n","# https://www.kaggle.com/code/shuvoalok/special-technique-for-image-classification#classification-of-image-using-Fourier-Transform-and--Wavelet-Transform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Nt_QNVnPhrq"},"outputs":[],"source":["# requires a lot of time ---> 9 hr +\n","# I concluded that it is not an optimal method for feature extraction\n","import cv2\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load your image dataset and labels\n","# You need to prepare your dataset and labels accordingly\n","\n","# Step 1: Feature Extraction (e.g., SIFT descriptors)\n","def extract_bovw(image):\n","  sift = cv2.SIFT_create()\n","\n","  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  keypoint, descriptor = sift.detectAndCompute(gray_image, None)\n","  return features\n","\n","# Step 2: Codebook Creation (K-means clustering)\n","def create_codebook(features, codebook_size):\n","    kmeans = KMeans(n_clusters=codebook_size)\n","    kmeans.fit(features)\n","    codebook = kmeans.cluster_centers_\n","    return codebook\n","\n","# Step 3: Generate Histograms of Visual Words\n","def generate_histograms(features, codebook):\n","    histograms = []\n","\n","    for feature in features:\n","        distances = np.linalg.norm(codebook - feature[:, np.newaxis], axis=2)\n","        nearest_codewords = np.argmin(distances, axis=1)\n","        histogram, _ = np.histogram(nearest_codewords, bins=np.arange(len(codebook) + 1))\n","        histograms.append(histogram)\n","\n","    return np.array(histograms)\n","\n","# Step 4: Train a Classifier (e.g., SVM)\n","def train_classifier(X_train, y_train):\n","    classifier = SVC(kernel='linear')\n","    classifier.fit(X_train, y_train)\n","    return classifier\n","\n","# Main Code\n","# extract features from image path\n","data_dir = '/content/drive/MyDrive/raw_dataset/apple_recognition/'\n","\n","labels = []\n","features = []\n","\n","for label in os.listdir(data_dir):\n","    label_dir = os.path.join(data_dir, label)\n","    if not os.path.isdir(label_dir):\n","        continue\n","    for image_file in os.listdir(label_dir):\n","        image_path = os.path.join(label_dir, image_file)\n","        image = cv2.imread(image_path)\n","        if image is not None:\n","          # get image features\n","            hog_features = extract_bovw(image)\n","            features.append(hog_features)\n","            labels.append(label)\n","\n","# Convert to numpy arrays\n","# X = np.array(features)\n","# target = np.array(labels)\n","\n","le = LabelEncoder()\n","labels_encoded = le.fit_transform(labels)\n","\n","X = np.vstack(features)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n","\n","# Create the codebook\n","codebook_size = 100  # Number of visual words\n","codebook = create_codebook(X_train, codebook_size)\n","\n","# Generate histograms of visual words for training and testing data\n","X_train_hist = generate_histograms(X_train, codebook)\n","X_test_hist = generate_histograms(X_test, codebook)\n","\n","# Train a classifier\n","classifier = train_classifier(X_train_hist, y_train)\n","\n","# Predict labels for test data\n","y_pred = classifier.predict(X_test_hist)\n","\n","# Evaluate the classifier\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPqVyxsLTN3l"},"outputs":[],"source":["# Classification of images using Fourier Transform and Wavelet Transform involves\n","# extracting features from images in the frequency domain and then using these features for \n","# classification.\n","\n","# Since this method create a lot dimension, we use PCA to reduce the dimensionality."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1316794,"status":"ok","timestamp":1717146863681,"user":{"displayName":"Arif Haidari","userId":"00811242659347129976"},"user_tz":-120},"id":"8vnWI5lO2Wjz","outputId":"bc0d1ab2-c481-46c0-a26a-43fd13f12f31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7146739130434783\n","Classification Report:\n","                          precision    recall  f1-score   support\n","\n","      Apple___Apple_scab       0.54      0.70      0.61        99\n","       Apple___Black_rot       0.68      0.65      0.67        75\n","Apple___Cedar_apple_rust       0.84      0.72      0.77        95\n","         Apple___healthy       0.89      0.78      0.83        99\n","\n","                accuracy                           0.71       368\n","               macro avg       0.74      0.71      0.72       368\n","            weighted avg       0.74      0.71      0.72       368\n","\n"]}],"source":["\n","import pywt\n","from sklearn.decomposition import PCA\n","\n","# Step 1: Feature Extraction - Fourier Transform\n","def extract_fourier_features(image_path, size=(128, 128)):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    image = cv2.resize(image, size)\n","    # Apply 2D Fourier Transform\n","    f_transform = np.fft.fft2(image)\n","    f_transform_shifted = np.fft.fftshift(f_transform)\n","    magnitude_spectrum = np.log(np.abs(f_transform_shifted) + 1)  # Log magnitude\n","    return magnitude_spectrum.flatten()\n","\n","# Step 2: Feature Extraction - Wavelet Transform\n","def extract_wavelet_features(image_path, wavelet='haar', level=1, size=(128, 128)):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    image = cv2.resize(image, size)\n","    # Apply 2D Wavelet Transform\n","    coeffs = pywt.wavedec2(image, wavelet, level=level)\n","    features = np.hstack([c.flatten() for c in coeffs[0:1] + sum([list(c) for c in coeffs[1:]], [])])\n","    return features\n","\n","# Prepare feature and label lists\n","fourier_features = []\n","wavelet_features = []\n","labels = []\n","\n","data_dir = '/content/drive/MyDrive/raw_dataset/apple_recognition/'\n","\n","for label in os.listdir(data_dir):\n","    label_dir = os.path.join(data_dir, label)\n","    if not os.path.isdir(label_dir):\n","        continue\n","    for image_file in os.listdir(label_dir):\n","        image_path = os.path.join(label_dir, image_file)\n","        if image_path is not None:\n","            # Extract features from image\n","            fourier = extract_fourier_features(image_path)\n","            wavelet = extract_wavelet_features(image_path)\n","            fourier_features.append(fourier)\n","            wavelet_features.append(wavelet)\n","            labels.append(label)\n","\n","# Convert feature lists to numpy arrays\n","fourier_features = np.array(fourier_features)\n","wavelet_features = np.array(wavelet_features)\n","\n","# Apply PCA to standardize feature dimensions\n","pca_fourier = PCA(n_components=100)  # Adjust the number of components as needed\n","pca_wavelet = PCA(n_components=100)  # Adjust the number of components as needed\n","fourier_features_pca = pca_fourier.fit_transform(fourier_features)\n","wavelet_features_pca = pca_wavelet.fit_transform(wavelet_features)\n","\n","# Combine Fourier and Wavelet features\n","X = np.hstack((fourier_features_pca, wavelet_features_pca))\n","\n","# Encode labels\n","le = LabelEncoder()\n","labels_encoded = le.fit_transform(labels)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n","\n","# Step 4: Train a Classifier (e.g., SVM)\n","def train_classifier(X_train, y_train):\n","    classifier = SVC(kernel='linear')\n","    classifier.fit(X_train, y_train)\n","    return classifier\n","\n","# Train the classifier\n","classifier = train_classifier(X_train, y_train)\n","\n","# Step 5: Predict and Evaluate\n","# Predict labels for test data\n","y_pred = classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsxOM-uKNLA2"},"outputs":[],"source":["# SIFT (Scale-Invariant Feature Transform): Detects and describes local features in images that are invariant to scale and rotation.\n","# SURF (Speeded-Up Robust Features): Similar to SIFT but faster.\n","# ORB (Oriented FAST and Rotated BRIEF): A fast and efficient alternative to SIFT and SURF.\n","\n","# Since ORB is the optimal method among three of them then we only continue with ORB"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368650,"status":"ok","timestamp":1717154817781,"user":{"displayName":"Arif Haidari","userId":"00811242659347129976"},"user_tz":-120},"id":"bkVNoO1GXGwH","outputId":"12f1f89a-810a-46aa-d794-b019dce04017"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5733695652173914\n","Classification Report:\n","                          precision    recall  f1-score   support\n","\n","      Apple___Apple_scab       0.51      0.43      0.47        99\n","       Apple___Black_rot       0.53      0.64      0.58        75\n","Apple___Cedar_apple_rust       0.64      0.64      0.64        95\n","         Apple___healthy       0.61      0.60      0.60        99\n","\n","                accuracy                           0.57       368\n","               macro avg       0.57      0.58      0.57       368\n","            weighted avg       0.57      0.57      0.57       368\n","\n"]}],"source":["def extract_features_orb(image):\n","    orb = cv2.ORB_create()\n","    keypoints, descriptors = orb.detectAndCompute(image, None)\n","    if descriptors is None:\n","        descriptors = np.array([])\n","    # Pad descriptors to a fixed length (e.g., 500)\n","    if descriptors.shape[0] < 500:\n","        descriptors = np.pad(descriptors, ((0, 500 - descriptors.shape[0]), (0, 0)), mode='constant')\n","    return descriptors.flatten()\n","\n","data_dir = '/content/drive/MyDrive/raw_dataset/apple_recognition/'\n","\n","labels = []\n","features = []\n","\n","for label in os.listdir(data_dir):\n","    label_dir = os.path.join(data_dir, label)\n","    if not os.path.isdir(label_dir):\n","        continue\n","    for image_file in os.listdir(label_dir):\n","        image_path = os.path.join(label_dir, image_file)\n","        image = cv2.imread(image_path)\n","        if image is not None:\n","            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","            # get image features\n","            orb_features = extract_features_orb(gray_image)\n","            features.append(orb_features)\n","            labels.append(label)\n","\n","# Convert to numpy arrays\n","X = np.array(features)\n","target = np.array(labels)\n","\n","le = LabelEncoder()\n","labels_encoded = le.fit_transform(target)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)\n","\n","# XGBoost model\n","xgb_model = XGBClassifier(n_estimators=100,\n","                               max_depth=3,\n","                               learning_rate=0.1,\n","                               n_jobs=-1,\n","                               subsample=0.8,\n","                               colsample_bytree=0.8,\n","                               objective='multi:softmax',\n","                               num_class=len(np.unique(labels_encoded)))\n","\n","# Train the model\n","xgb_model.fit(X_train, y_train, eval_metric='mlogloss', eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n","\n","# Predictions\n","y_pred = xgb_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruc8MRewXrkz"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOAxsdn+7lWbcUvQJ4XiZbv","mount_file_id":"12n4HCv0xBjCgLq1mtpJpt8fkUSI33Xtj","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
